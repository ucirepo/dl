{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Dense, Embedding\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split\n# Sample dataset\nnames = ['John', 'Jane', 'Alice', 'Bob', 'Michael', 'Mary', 'David', 'Sarah', 'James', 'Emily',\n         'William', 'Emma', 'Matthew', 'Olivia', 'Daniel', 'Sophia', 'Christopher', 'Isabella', 'Andrew', 'Ava']\ngenders = ['male', 'female', 'female', 'male', 'male', 'female', 'male', 'female', 'male', 'female',\n           'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female', 'male', 'female']\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n# Create Vocabulary\ntokenizer = Tokenizer(char_level=True)\ntokenizer.fit_on_texts(names)\nprint(\"Vocabulary:\", tokenizer.word_index)\n\n# Convert names to numerical representation\nX = tokenizer.texts_to_sequences(names)\nprint(X)\n\n# Pad sequences to a fixed length\nmax_length = max(len(seq) for seq in X)\nX = pad_sequences(X, maxlen=max_length, padding='post')\nprint(X)\n# Convert to numpy array\nX = np.array(X)\n# One-hot encode genders\ny = np.array([1 if gender == 'male' else 0 for gender in genders])\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(len(tokenizer.word_index))\nprint(X.shape[1])\n# Build SimpleRNN model\nmodel = Sequential()\nmodel.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=10, input_length=X.shape[1]))\nmodel.add(SimpleRNN(10))\nmodel.add(Dense(1, activation='sigmoid'))\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=10, batch_size=1, verbose=1)\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LS_7DyJTSr1F","outputId":"c523ff44-f9a3-4a8c-fb87-6817f910c166"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary: {'a': 1, 'i': 2, 'e': 3, 'l': 4, 'm': 5, 'h': 6, 'o': 7, 'r': 8, 's': 9, 'n': 10, 'd': 11, 'j': 12, 'c': 13, 'b': 14, 'v': 15, 'w': 16, 't': 17, 'y': 18, 'p': 19}\n","[[12, 7, 6, 10], [12, 1, 10, 3], [1, 4, 2, 13, 3], [14, 7, 14], [5, 2, 13, 6, 1, 3, 4], [5, 1, 8, 18], [11, 1, 15, 2, 11], [9, 1, 8, 1, 6], [12, 1, 5, 3, 9], [3, 5, 2, 4, 18], [16, 2, 4, 4, 2, 1, 5], [3, 5, 5, 1], [5, 1, 17, 17, 6, 3, 16], [7, 4, 2, 15, 2, 1], [11, 1, 10, 2, 3, 4], [9, 7, 19, 6, 2, 1], [13, 6, 8, 2, 9, 17, 7, 19, 6, 3, 8], [2, 9, 1, 14, 3, 4, 4, 1], [1, 10, 11, 8, 3, 16], [1, 15, 1]]\n","[[12  7  6 10  0  0  0  0  0  0  0]\n"," [12  1 10  3  0  0  0  0  0  0  0]\n"," [ 1  4  2 13  3  0  0  0  0  0  0]\n"," [14  7 14  0  0  0  0  0  0  0  0]\n"," [ 5  2 13  6  1  3  4  0  0  0  0]\n"," [ 5  1  8 18  0  0  0  0  0  0  0]\n"," [11  1 15  2 11  0  0  0  0  0  0]\n"," [ 9  1  8  1  6  0  0  0  0  0  0]\n"," [12  1  5  3  9  0  0  0  0  0  0]\n"," [ 3  5  2  4 18  0  0  0  0  0  0]\n"," [16  2  4  4  2  1  5  0  0  0  0]\n"," [ 3  5  5  1  0  0  0  0  0  0  0]\n"," [ 5  1 17 17  6  3 16  0  0  0  0]\n"," [ 7  4  2 15  2  1  0  0  0  0  0]\n"," [11  1 10  2  3  4  0  0  0  0  0]\n"," [ 9  7 19  6  2  1  0  0  0  0  0]\n"," [13  6  8  2  9 17  7 19  6  3  8]\n"," [ 2  9  1 14  3  4  4  1  0  0  0]\n"," [ 1 10 11  8  3 16  0  0  0  0  0]\n"," [ 1 15  1  0  0  0  0  0  0  0  0]]\n","19\n","11\n","Epoch 1/10\n","16/16 [==============================] - 3s 4ms/step - loss: 0.6856 - accuracy: 0.6250\n","Epoch 2/10\n","16/16 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.8750\n","Epoch 3/10\n","16/16 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.8750\n","Epoch 4/10\n","16/16 [==============================] - 0s 6ms/step - loss: 0.6058 - accuracy: 0.9375\n","Epoch 5/10\n","16/16 [==============================] - 0s 6ms/step - loss: 0.5541 - accuracy: 0.9375\n","Epoch 6/10\n","16/16 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.9375\n","Epoch 7/10\n","16/16 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.9375\n","Epoch 8/10\n","16/16 [==============================] - 0s 6ms/step - loss: 0.2947 - accuracy: 1.0000\n","Epoch 9/10\n","16/16 [==============================] - 0s 6ms/step - loss: 0.2135 - accuracy: 1.0000\n","Epoch 10/10\n","16/16 [==============================] - 0s 7ms/step - loss: 0.1574 - accuracy: 1.0000\n","Test Accuracy: 75.00%\n"]}],"execution_count":3},{"cell_type":"code","source":"# Define a function to predict gender for a given name\ndef predict_gender(name):\n    # Convert the name to numerical representation\n    name_seq = tokenizer.texts_to_sequences([name])\n    # Pad sequences to a fixed length\n    max_length = max(len(name_seq) for name_seq in X)\n    name_seq = pad_sequences(name_seq, maxlen=max_length, padding='post')\n    # Convert to numpy array\n    name_seq = np.array(name_seq)\n    # Make the prediction\n    prediction = model.predict(name_seq)[0][0]\n    # Convert prediction to gender label\n    gender = 'male' if prediction >= 0.5 else 'female'\n    return gender\nrandom_name = 'Emma'\npredicted_gender = predict_gender(random_name)\nprint(f\"The predicted gender for the name '{random_name}' is: {predicted_gender}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QC2PyRIhTJQ3","outputId":"6228f802-09cc-4fe5-fcda-3d259d2f5c43"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 208ms/step\n","The predicted gender for the name 'Emma' is: female\n"]}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"id":"AM-D2e1QTvC5"},"outputs":[],"execution_count":null}]}